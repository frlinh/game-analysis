{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4bfee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "import datetime as dt\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests, os, bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a600537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 104.0.5112\n",
      "[WDM] - Get LATEST chromedriver version for 104.0.5112 google-chrome\n",
      "[WDM] - There is no [mac64] chromedriver for browser 104.0.5112 in cache\n",
      "[WDM] - About to download new driver from https://chromedriver.storage.googleapis.com/104.0.5112.79/chromedriver_mac64.zip\n",
      "[WDM] - Driver has been saved in cache [/Users/adriennezane/.wdm/drivers/chromedriver/mac64/104.0.5112.79]\n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0fa7f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visit the mars nasa news site\n",
    "url = 'https://www.leagueoflegends.com/en-us/champions/'\n",
    "browser.visit(url)\n",
    "# Optional delay for loading the page\n",
    "browser.is_element_present_by_css('div.list_text', wait_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "924fc9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML\n",
    "html = browser.html\n",
    "html_soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9315c8f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 2) (699721480.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [11]\u001b[0;36m\u001b[0m\n\u001b[0;31m    title = html_soup.find('hero\")\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "# Scrape the Title\n",
    "title = html_soup.find('hero\")\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40e684d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<splinter.driver.webdriver.WebDriverElement at 0x7fe9bed8c8e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and click the full image button\n",
    "full_image_elem = browser.find_by_tag('span')[1]\n",
    "#<span data-testid=\"list-0:image\" class=\"style__ImageContainer-n3ovyt-1 ajxce\"\"http\n",
    "full_image_elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4092a5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://images.contentstack.io/v3/assets/blt731acb42bb3d1659/blt54ddb4c66be148b2/62cca36fb5fe933768646d93/TEXTLESS-NILAH_YouTube_Champion_Spotlight_v01_TTan_opt.jpg?quality=90&crop=12%3A7&width=300 to folder...\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: 'League'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to folder...\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (src))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#imageFile = open(os.path.join('League', 'Champion.jpg'), 'wb')\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m imageFile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLeague\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m res\u001b[38;5;241m.\u001b[39miter_content(\u001b[38;5;241m100000\u001b[39m):\n\u001b[1;32m     25\u001b[0m     imageFile\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: 'League'"
     ]
    }
   ],
   "source": [
    "# Visit the mars nasa news site\n",
    "url = 'https://www.leagueoflegends.com/en-us/champions/'\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "# Create the folder in path.\n",
    "os.makedirs('League', exist_ok = True)\n",
    "# Find the images.\n",
    "soup = bs4.BeautifulSoup(res.text, 'html.parser')\n",
    "all_post = soup.select('img[src]')\n",
    "\n",
    "for post in all_post:\n",
    "    src = post.get('src')\n",
    "    if not src:\n",
    "        print('Could not find image.')\n",
    "    \n",
    "    # Download the images.\n",
    "    else:\n",
    "        res = requests.get(src)\n",
    "        res.raise_for_status()\n",
    "        # Saves the images to League folder.\n",
    "        print('Downloading %s to folder...' % (src))\n",
    "        #imageFile = open(os.path.join('League', 'Champion.jpg'), 'wb')\n",
    "        imageFile = open('League')\n",
    "        for chunk in res.iter_content(100000):\n",
    "            imageFile.write(chunk)\n",
    "        imageFile.close()\n",
    "        \n",
    "print('Done.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "faba601f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m all_post \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg[src]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m all_post:\n\u001b[0;32m---> 12\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/([\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mw_-]+[.](jpg|gif|png))$\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[1;32m     14\u001b[0m          \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegex didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match with the url: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(post))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.10/re.py:200\u001b[0m, in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# Visit the mars nasa news site\n",
    "url = 'https://www.leagueoflegends.com/en-us/champions/'\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "# Create the folder in path.\n",
    "os.makedirs('League', exist_ok = True)\n",
    "# Find the images.\n",
    "soup = bs4.BeautifulSoup(res.text, 'html.parser')\n",
    "all_post = soup.select('img[src]')\n",
    "\n",
    "for post in all_post:\n",
    "    filename = re.search(r'/([\\w_-]+[.](jpg|gif|png))$', post)\n",
    "    if not filename:\n",
    "         print(\"Regex didn't match with the url: {}\".format(post))\n",
    "         continue\n",
    "    with open(filename.group(1), 'wb') as f:\n",
    "        if 'http' not in post:\n",
    "            # sometimes an image source can be relative \n",
    "            # if it is provide the base url which also happens \n",
    "            # to be the site variable atm. \n",
    "            post = '{}{}'.format(site, post)\n",
    "        response = requests.get(post)\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "417f2255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://images.contentstack.io/v3/assets/blt731acb42bb3d1659/blt54ddb4c66be148b2/62cca36fb5fe933768646d93/TEXTLESS-NILAH_YouTube_Champion_Spotlight_v01_TTan_opt.jpg?quality=90&crop=12%3A7&width=300'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #class=\"style__NoScriptImg-g183su-0 style__Img-g183su-1 cipsic dBitJH\" \n",
    " # Find the relative image url\n",
    "img_url_rel = soup.find('img', class_='style__NoScriptImg-g183su-0 style__Img-g183su-1 cipsic dBitJH').get('src')\n",
    "img_url_rel \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7b0bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
