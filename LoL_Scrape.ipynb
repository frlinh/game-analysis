{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4bfee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "import datetime as dt\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests, os, bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a600537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-11 17:01:30,230 INFO ====== WebDriver manager ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 105.0.5195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-11 17:01:30,232 INFO Current google-chrome version is 105.0.5195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Get LATEST chromedriver version for 105.0.5195 google-chrome\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-11 17:01:30,233 INFO Get LATEST chromedriver version for 105.0.5195 google-chrome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\LASAGNA\\.wdm\\drivers\\chromedriver\\win32\\105.0.5195.52\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-11 17:01:30,346 INFO Driver [C:\\Users\\LASAGNA\\.wdm\\drivers\\chromedriver\\win32\\105.0.5195.52\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0fa7f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visit the mars nasa news site\n",
    "url = 'https://www.leagueoflegends.com/en-us/champions/'\n",
    "browser.visit(url)\n",
    "# Optional delay for loading the page\n",
    "browser.is_element_present_by_css('div.list_text', wait_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "924fc9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML\n",
    "html = browser.html\n",
    "html_soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9315c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the Title\n",
    "title = html_soup.find(\"hero\")\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e684d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and click the full image button\n",
    "full_image_elem = browser.find_by_tag('span')[1]\n",
    "#<span data-testid=\"list-0:image\" class=\"style__ImageContainer-n3ovyt-1 ajxce\"\"http\n",
    "full_image_elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4092a5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://images.contentstack.io/v3/assets/blt731acb42bb3d1659/blt54ddb4c66be148b2/62cca36fb5fe933768646d93/TEXTLESS-NILAH_YouTube_Champion_Spotlight_v01_TTan_opt.jpg?quality=90&crop=12%3A7&width=300 to folder...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'League'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to folder...\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (src))\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#imageFile = open(os.path.join('League', 'Champion.jpg'), 'wb')\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m imageFile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLeague\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m res\u001b[38;5;241m.\u001b[39miter_content(\u001b[38;5;241m100000\u001b[39m):\n\u001b[0;32m     25\u001b[0m     imageFile\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'League'"
     ]
    }
   ],
   "source": [
    "# Visit the mars nasa news site\n",
    "url = 'https://www.leagueoflegends.com/en-us/champions/'\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "# Create the folder in path.\n",
    "os.makedirs('/League/', exist_ok = True)\n",
    "# Find the images.\n",
    "soup = bs4.BeautifulSoup(res.text, 'html.parser')\n",
    "all_post = soup.select('img[src]')\n",
    "\n",
    "for post in all_post:\n",
    "    src = post.get('src')\n",
    "    if not src:\n",
    "        print('Could not find image.')\n",
    "    \n",
    "    # Download the images.\n",
    "    else:\n",
    "        res = requests.get(src)\n",
    "        res.raise_for_status()\n",
    "        # Saves the images to League folder.\n",
    "        print('Downloading %s to folder...' % (src))\n",
    "        #imageFile = open(os.path.join('League', 'Champion.jpg'), 'wb')\n",
    "        imageFile = open('League')\n",
    "        for chunk in res.iter_content(100000):\n",
    "            imageFile.write(chunk)\n",
    "        imageFile.close()\n",
    "        \n",
    "print('Done.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faba601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the mars nasa news site\n",
    "url = 'https://www.leagueoflegends.com/en-us/champions/'\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "# Create the folder in path.\n",
    "os.makedirs('League', exist_ok = True)\n",
    "# Find the images.\n",
    "soup = bs4.BeautifulSoup(res.text, 'html.parser')\n",
    "all_post = soup.select('img[src]')\n",
    "\n",
    "for post in all_post:\n",
    "    filename = re.search(r'/([\\w_-]+[.](jpg|gif|png))$', post)\n",
    "    if not filename:\n",
    "         print(\"Regex didn't match with the url: {}\".format(post))\n",
    "         continue\n",
    "    with open(filename.group(1), 'wb') as f:\n",
    "        if 'http' not in post:\n",
    "            # sometimes an image source can be relative \n",
    "            # if it is provide the base url which also happens \n",
    "            # to be the site variable atm. \n",
    "            post = '{}{}'.format(site, post)\n",
    "        response = requests.get(post)\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f2255",
   "metadata": {},
   "outputs": [],
   "source": [
    " #class=\"style__NoScriptImg-g183su-0 style__Img-g183su-1 cipsic dBitJH\" \n",
    " # Find the relative image url\n",
    "img_url_rel = soup.find('img', class_='style__NoScriptImg-g183su-0 style__Img-g183su-1 cipsic dBitJH').get('src')\n",
    "img_url_rel \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7b0bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
